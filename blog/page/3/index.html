
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Coder Blog VJIA</title>
  <meta name="author" content="Vincent J">

  
  <meta name="description" content="1) 配置hadoop-env.sh 走到这一步时，是参照Michael-noll.com上的内容，但是需要配置$HADOOP_HOME/conf/hadoop-env.sh了，我不清楚他在写此篇博客时是基于Hadoop哪个版本，但是在我当前版本-2.0.5-alpha，并没有此目录； &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://icersummer.github.io/blog/page/3">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="Coder Blog VJIA" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  

</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">Coder Blog VJIA</a></h1>
  
    <h2>A blogging framework for hackers.</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:icersummer.github.io" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/08/01/single-node-setup-of-hadoop/">Single-Node Setup of Hadoop</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-08-01T21:20:03-07:00" pubdate data-updated="true">Aug 1<span>st</span>, 2013</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h2>1) 配置hadoop-env.sh</h2>

<p>走到这一步时，是参照<a href="http://www.michael-noll.com/tutorials/running-hadoop-on-ubuntu-linux-single-node-cluster/">Michael-noll.com上的内容</a>，但是需要配置$HADOOP_HOME/conf/hadoop-env.sh了，我不清楚他在写此篇博客时是基于Hadoop哪个版本，但是在我当前版本-2.0.5-alpha，并没有此目录；所以以下内容和记录转向参考<a href="http://raseshmori.wordpress.com/2012/09/23/install-hadoop-2-0-1-yarn-nextgen/">Install Hadoop 2.0.1-alpha Yarn Next-Gen</a>.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>hduser@ubuntu:~/hadoop-2.0.5-alpha/etc/hadoop$ hadoop version
</span><span class='line'>Hadoop 2.0.5-alpha
</span><span class='line'>Subversion http://svn.apache.org/repos/asf/hadoop/common -r 1488459
</span><span class='line'>Compiled by jenkins on 2013-06-01T04:05Z
</span><span class='line'>From source with checksum c8f4bd45ac25c31b815f311b32ef17
</span><span class='line'>This command was run using /home/hduser/hadoop-2.0.5-alpha/share/hadoop/common/hadoop-common-2.0.5-alpha.jar</span></code></pre></td></tr></table></div></figure>


<h2>2) 需要安装Tarball么，先不安装，待定。</h2>

<h2>3) 配置环境变量</h2>

<p>.bashrc:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>// configure follow raseshmori.wordpress.com
</span><span class='line'>HADOOP_MAPRED_HOME=$HADOOP_HOME
</span><span class='line'>export HADOOP_MAPRED_HOME
</span><span class='line'>
</span><span class='line'>HADOOP_COMMON_HOME=$HADOOP_HOME
</span><span class='line'>export HADOOP_COMMON_HOME
</span><span class='line'>
</span><span class='line'>HADOOP_HDFS_HOME=$HADOOP_HOME
</span><span class='line'>export HADOOP_HDFS_HOME
</span><span class='line'>
</span><span class='line'>HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop
</span><span class='line'>export HADOOP_HDFS_HOME</span></code></pre></td></tr></table></div></figure>


<h2>4) 创建2个目录，用于存储namenode和datanode的数据</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>hduser@ubuntu:~$ pwd
</span><span class='line'>/home/hduser
</span><span class='line'>hduser@ubuntu:~$ ls
</span><span class='line'>bak.of.bashrc  examples.desktop  hadoop-2.0.5-alpha  hadoop-2.0.5-alpha.tar.gz
</span><span class='line'>hduser@ubuntu:~$ mkdir hadoop_data
</span><span class='line'>hduser@ubuntu:~$ cd hadoop_data/
</span><span class='line'>hduser@ubuntu:~/hadoop_data$ ls
</span><span class='line'>hduser@ubuntu:~/hadoop_data$ mkdir hdfs
</span><span class='line'>hduser@ubuntu:~/hadoop_data$ cd hdfs/
</span><span class='line'>hduser@ubuntu:~/hadoop_data/hdfs$ mkdir namenode
</span><span class='line'>hduser@ubuntu:~/hadoop_data/hdfs$ mkdir datanode
</span><span class='line'>hduser@ubuntu:~/hadoop_data/hdfs$ pwd
</span><span class='line'>/home/hduser/hadoop_data/hdfs</span></code></pre></td></tr></table></div></figure>


<h2>5) 设置Properties在Config文件中：</h2>

<ul>
<li>yarn-site.xml ($HADOOP_HOME/etc/hadoop)</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>// Site specifc YARN configuration properties
</span><span class='line'>&lt;property&gt;
</span><span class='line'>  &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
</span><span class='line'>  &lt;value&gt;mapreduce.shuffle&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>  &lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt;
</span><span class='line'>  &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;</span></code></pre></td></tr></table></div></figure>


<ul>
<li>core-site.xml ($HADOOP_HOME/etc/hadoop)</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&lt;configuration&gt;
</span><span class='line'>
</span><span class='line'> &lt;property&gt;
</span><span class='line'>    &lt;name&gt;fs.default.name&lt;/name&gt;
</span><span class='line'>    &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;
</span><span class='line'> &lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;/configuration&gt;</span></code></pre></td></tr></table></div></figure>


<ul>
<li>hdfs-site.xml</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&lt;configuration&gt;
</span><span class='line'>
</span><span class='line'> &lt;property&gt;
</span><span class='line'>    &lt;name&gt;dfs.replication&lt;/name&gt;
</span><span class='line'>    &lt;value&gt;1&lt;/value&gt;
</span><span class='line'> &lt;/property&gt;
</span><span class='line'>
</span><span class='line'> &lt;property&gt;
</span><span class='line'>   &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;
</span><span class='line'>   &lt;value&gt;file:/home/hduser/hadoop_data/hdfs/namenode&lt;/value&gt;
</span><span class='line'> &lt;/property&gt;
</span><span class='line'>
</span><span class='line'> &lt;property&gt;
</span><span class='line'>   &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;
</span><span class='line'>   &lt;value&gt;file:/home/hduser/hadoop_data/hdfs/datanode&lt;/value&gt;
</span><span class='line'> &lt;/property&gt;
</span><span class='line'>&lt;/configuration&gt;</span></code></pre></td></tr></table></div></figure>


<ul>
<li>mapred-site.xml</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&lt;configuration&gt;
</span><span class='line'> &lt;property&gt;
</span><span class='line'>   &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
</span><span class='line'>   &lt;value&gt;yarn&lt;/value&gt;
</span><span class='line'> &lt;/property&gt;
</span><span class='line'>&lt;/configuration&gt;</span></code></pre></td></tr></table></div></figure>


<h2>6) 格式化namenode</h2>

<blockquote><p>This step is needed only for the first time. Doing it every time will result in loss of content on HDFS.</p>

<blockquote><p>注意1 > 1.1注意 > 1.2注意</p></blockquote></blockquote>

<p><code>hduser@ubuntu:~/hadoop-2.0.5-alpha/bin$ ./hadoop namenode -format</code></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>hduser@ubuntu:~/hadoop-2.0.5-alpha/bin$ ./hadoop namenode -format
</span><span class='line'>DEPRECATED: Use of this script to execute hdfs command is deprecated.
</span><span class='line'>Instead use the hdfs command for it.
</span><span class='line'>
</span><span class='line'>13/07/31 20:42:11 INFO namenode.NameNode: STARTUP_MSG: 
</span><span class='line'>/************************************************************
</span><span class='line'>STARTUP_MSG: Starting NameNode
</span><span class='line'>STARTUP_MSG:   host = ubuntu/127.0.1.1
</span><span class='line'>STARTUP_MSG:   args = [-format]
</span><span class='line'>STARTUP_MSG:   version = 2.0.5-alpha
</span><span class='line'>STARTUP_MSG:   classpath = /home/hduser/hadoop-2.0.5-alpha/etc/hadoop:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/common/lib/jettison-1.1.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/common/lib/snappy-java-1.0.3.2.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/common/lib/jackson-mapper-asl-1.8.8.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/common/lib/commons-cli-1.2.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/common/lib/jsp-api-2.1.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/common/lib/xmlenc-0.52.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/common/lib/guava-11.0.2.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/common/lib/protobuf-java-2.4.0a.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/common/lib/commons-el-1.0.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/common/lib/jetty-6.1.26.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/common/lib/jets3t-0.6.1.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/common/lib/asm-3.2.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/common/lib/zookeeper-3.4.2.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/common/lib/commons-digester-1.8.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/common/lib/avro-1.5.3.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/common/lib/jersey-server-1.8.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/common/lib/jackson-core-asl-1.8.8.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/common/lib/commons-math-2.1.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/common/lib/activation-1.1.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/common/lib/commons-lang-2.5.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/common/lib/paranamer-2.3.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/common/lib/servlet-api-2.5.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/common/lib/jsch-0.1.42.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/common/lib/commons-io-2.1.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/common/lib/jersey-core-1.8.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/common/lib/commons-logging-1.1.1.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/common/lib/slf4j-log4j12-1.6.1.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/common/lib/commons-net-3.1.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/common/lib/log4j-1.2.17.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/common/lib/jackson-xc-1.8.8.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/common/lib/hadoop-auth-2.0.5-alpha.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/common/lib/jersey-json-1.8.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/common/lib/jackson-jaxrs-1.8.8.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/common/lib/stax-api-1.0.1.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/common/lib/commons-codec-1.4.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/common/lib/hadoop-annotations-2.0.5-alpha.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/common/lib/kfs-0.3.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/common/lib/slf4j-api-1.6.1.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/common/hadoop-common-2.0.5-alpha.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/common/hadoop-common-2.0.5-alpha-tests.jar:/home/hduser/hadoop-2.0.5-alpha/contrib/capacity-scheduler/*.jar:/home/hduser/hadoop-2.0.5-alpha/contrib/capacity-scheduler/*.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/hdfs:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/hdfs/lib/jackson-mapper-asl-1.8.8.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/hdfs/lib/protobuf-java-2.4.0a.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/hdfs/lib/asm-3.2.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/hdfs/lib/jersey-server-1.8.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/hdfs/lib/jackson-core-asl-1.8.8.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/hdfs/lib/commons-lang-2.5.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/hdfs/lib/commons-io-2.1.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/hdfs/lib/jersey-core-1.8.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/hdfs/lib/commons-logging-1.1.1.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/hdfs/hadoop-hdfs-2.0.5-alpha-tests.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/hdfs/hadoop-hdfs-2.0.5-alpha.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/yarn/lib/snappy-java-1.0.3.2.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/yarn/lib/protobuf-java-2.4.0a.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/yarn/lib/netty-3.5.11.Final.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/yarn/lib/asm-3.2.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/yarn/lib/avro-1.5.3.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/yarn/lib/junit-4.8.2.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/yarn/lib/jersey-server-1.8.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/yarn/lib/commons-io-2.1.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/yarn/lib/jersey-core-1.8.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/yarn/lib/jersey-guice-1.8.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/yarn/lib/guice-3.0.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/yarn/lib/javax.inject-1.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/yarn/lib/hadoop-annotations-2.0.5-alpha.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.0.5-alpha.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/yarn/hadoop-yarn-client-2.0.5-alpha.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/yarn/hadoop-yarn-site-2.0.5-alpha.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/yarn/hadoop-yarn-server-tests-2.0.5-alpha.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/yarn/hadoop-yarn-api-2.0.5-alpha.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/yarn/hadoop-yarn-server-common-2.0.5-alpha.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/yarn/hadoop-yarn-common-2.0.5-alpha.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.0.5-alpha.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.0.5-alpha.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.0.5-alpha.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.0.5-alpha.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/mapreduce/lib/snappy-java-1.0.3.2.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/mapreduce/lib/protobuf-java-2.4.0a.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/mapreduce/lib/netty-3.5.11.Final.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/mapreduce/lib/avro-1.5.3.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/mapreduce/lib/junit-4.8.2.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/mapreduce/lib/jersey-server-1.8.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/mapreduce/lib/jackson-core-asl-1.8.8.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/mapreduce/lib/commons-io-2.1.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/mapreduce/lib/jersey-core-1.8.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/mapreduce/lib/jersey-guice-1.8.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/mapreduce/lib/hadoop-annotations-2.0.5-alpha.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.0.5-alpha.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.0.5-alpha-tests.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.0.5-alpha.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.0.5-alpha.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.0.5-alpha.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.0.5-alpha.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.0.5-alpha.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.0.5-alpha.jar:/home/hduser/hadoop-2.0.5-alpha/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.0.5-alpha.jar
</span><span class='line'>STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/common -r 1488459; compiled by 'jenkins' on 2013-06-01T04:05Z
</span><span class='line'>STARTUP_MSG:   java = 1.7.0_25
</span><span class='line'>************************************************************/
</span><span class='line'>Formatting using clusterid: CID-dcd1e06d-a0f7-450c-b5c8-9f81f40e0114
</span><span class='line'>13/07/31 20:42:12 INFO util.HostsFileReader: Refreshing hosts (include/exclude) list
</span><span class='line'>13/07/31 20:42:12 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
</span><span class='line'>13/07/31 20:42:13 INFO blockmanagement.BlockManager: dfs.block.access.token.enable=false
</span><span class='line'>13/07/31 20:42:13 INFO blockmanagement.BlockManager: defaultReplication         = 1
</span><span class='line'>13/07/31 20:42:13 INFO blockmanagement.BlockManager: maxReplication             = 512
</span><span class='line'>13/07/31 20:42:13 INFO blockmanagement.BlockManager: minReplication             = 1
</span><span class='line'>13/07/31 20:42:13 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2
</span><span class='line'>13/07/31 20:42:13 INFO blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
</span><span class='line'>13/07/31 20:42:13 INFO blockmanagement.BlockManager: replicationRecheckInterval = 3000
</span><span class='line'>13/07/31 20:42:13 INFO blockmanagement.BlockManager: encryptDataTransfer        = false
</span><span class='line'>13/07/31 20:42:13 INFO namenode.FSNamesystem: fsOwner             = hduser (auth:SIMPLE)
</span><span class='line'>13/07/31 20:42:13 INFO namenode.FSNamesystem: supergroup          = supergroup
</span><span class='line'>13/07/31 20:42:13 INFO namenode.FSNamesystem: isPermissionEnabled = true
</span><span class='line'>13/07/31 20:42:13 INFO namenode.FSNamesystem: HA Enabled: false
</span><span class='line'>13/07/31 20:42:13 INFO namenode.FSNamesystem: Append Enabled: true
</span><span class='line'>13/07/31 20:42:13 INFO namenode.NameNode: Caching file names occuring more than 10 times
</span><span class='line'>13/07/31 20:42:13 INFO namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
</span><span class='line'>13/07/31 20:42:13 INFO namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
</span><span class='line'>13/07/31 20:42:13 INFO namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
</span><span class='line'>Re-format filesystem in Storage Directory /home/hduser/hadoop_data/hdfs/namenode ? (Y or N) y
</span><span class='line'>13/07/31 20:42:19 INFO common.Storage: Storage directory /home/hduser/hadoop_data/hdfs/namenode has been successfully formatted.
</span><span class='line'>13/07/31 20:42:19 INFO namenode.FSImage: Saving image file /home/hduser/hadoop_data/hdfs/namenode/current/fsimage.ckpt_0000000000000000000 using no compression
</span><span class='line'>13/07/31 20:42:19 INFO namenode.FSImage: Image file of size 121 saved in 0 seconds.
</span><span class='line'>13/07/31 20:42:19 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid &gt;= 0
</span><span class='line'>13/07/31 20:42:19 INFO util.ExitUtil: Exiting with status 0
</span><span class='line'>13/07/31 20:42:19 INFO namenode.NameNode: SHUTDOWN_MSG: 
</span><span class='line'>/************************************************************
</span><span class='line'>SHUTDOWN_MSG: Shutting down NameNode at ubuntu/127.0.1.1
</span><span class='line'>************************************************************/</span></code></pre></td></tr></table></div></figure>


<h2>7) start HDFS processes</h2>

<p><em>Name node</em></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>hduser@ubuntu:~/hadoop-2.0.5-alpha/sbin$ ./hadoop-daemon
</span><span class='line'>hadoop-daemon.sh   hadoop-daemons.sh  
</span><span class='line'>hduser@ubuntu:~/hadoop-2.0.5-alpha/sbin$ ./hadoop-daemon.sh  start namenode
</span><span class='line'>starting namenode, logging to /home/hduser/hadoop-2.0.5-alpha/logs/hadoop-hduser-namenode-ubuntu.out
</span><span class='line'>hduser@ubuntu:~/hadoop-2.0.5-alpha/sbin$ jps
</span><span class='line'>The program 'jps' can be found in the following packages:
</span><span class='line'> * openjdk-6-jdk
</span><span class='line'> * openjdk-7-jdk
</span><span class='line'>Ask your administrator to install one of them
</span><span class='line'>// 不清楚jps命令是什么，但是这里应该对安装没有影响，已经安装了Oracle JDK 1.7</span></code></pre></td></tr></table></div></figure>


<p><em>Data node</em></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>hduser@ubuntu:~/hadoop-2.0.5-alpha/sbin$ ./hadoop-daemon.sh start datanode
</span><span class='line'>starting datanode, logging to /home/hduser/hadoop-2.0.5-alpha/logs/hadoop-hduser-datanode-ubuntu.out</span></code></pre></td></tr></table></div></figure>


<h2>8) start Hadoop Map-Reduce Processes</h2>

<p><em>Resource Manager</em></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>hduser@ubuntu:~/hadoop-2.0.5-alpha$ sbin/yarn-daemon.sh start resourcemanager
</span><span class='line'>starting resourcemanager, logging to /home/hduser/hadoop-2.0.5-alpha/logs/yarn-hduser-resourcemanager-ubuntu.out</span></code></pre></td></tr></table></div></figure>


<p><em>Node Manager</em></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>hduser@ubuntu:~/hadoop-2.0.5-alpha$ sbin/yarn-daemon.sh start nodemanager
</span><span class='line'>starting nodemanager, logging to /home/hduser/hadoop-2.0.5-alpha/logs/yarn-hduser-nodemanager-ubuntu.out</span></code></pre></td></tr></table></div></figure>


<p><em>Job History Server</em></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>hduser@ubuntu:~/hadoop-2.0.5-alpha$ sbin/mr-jobhistory-daemon.sh start historyserver
</span><span class='line'>starting historyserver, logging to /home/hduser/hadoop-2.0.5-alpha/logs/mapred-hduser-historyserver-ubuntu.out</span></code></pre></td></tr></table></div></figure>


<h2>9) 运行一个简单/经典的字符统计示例，来验证安装是否成功</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>hduser@ubuntu:~/hadoop-2.0.5-alpha$ mkdir in
</span><span class='line'>hduser@ubuntu:~/hadoop-2.0.5-alpha$ cat &gt; in/file    //这个命令不错
</span><span class='line'>This is one line
</span><span class='line'>This is another one</span></code></pre></td></tr></table></div></figure>


<p>Add this directory to HDFS:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>hduser@ubuntu:~/hadoop-2.0.5-alpha$ bin/hadoop dfs -copyFromLocal in /in
</span><span class='line'>DEPRECATED: Use of this script to execute hdfs command is deprecated.
</span><span class='line'>Instead use the hdfs command for it.
</span><span class='line'>// note: dfs命令已经被弃用，应用fs命令，见[fs replace dfs](http://stackoverflow.com/questions/11715082/why-is-it-keep-showing-deprecated-error-when-running-hadoop-or-dfs-command)
</span><span class='line'>hduser@ubuntu:~/hadoop-2.0.5-alpha$ ./bin/hadoop fs -copyFromLocal in /in</span></code></pre></td></tr></table></div></figure>


<p>运行share目录中提供的wordcount示例：</p>

<p><code>hduser@ubuntu:~/hadoop-2.0.5-alpha/logs$ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.0.5-alpha.jar wordcount /in /out3</code></p>

<p>to continue&hellip;</p>

<h2>10) 运行<em>netstat</em>命令，查看是否Hadoop监听在已经配置的端口</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>hduser@ubuntu:~/hadoop-2.0.5-alpha/logs$ sudo netstat -plten | grep java
</span><span class='line'>[sudo] password for hduser: 
</span><span class='line'>tcp        0      0 0.0.0.0:19888           0.0.0.0:*               LISTEN      1001       33451       6931/java       
</span><span class='line'>tcp        0      0 0.0.0.0:50070           0.0.0.0:*               LISTEN      1001       31961       6436/java       
</span><span class='line'>tcp        0      0 0.0.0.0:50010           0.0.0.0:*               LISTEN      1001       32345       6510/java       
</span><span class='line'>tcp        0      0 0.0.0.0:50075           0.0.0.0:*               LISTEN      1001       32352       6510/java       
</span><span class='line'>tcp        0      0 0.0.0.0:10020           0.0.0.0:*               LISTEN      1001       33459       6931/java       
</span><span class='line'>tcp        0      0 0.0.0.0:50020           0.0.0.0:*               LISTEN      1001       32358       6510/java       
</span><span class='line'>tcp        0      0 127.0.0.1:9000          0.0.0.0:*               LISTEN      1001       31785       6436/java       
</span><span class='line'>tcp6       0      0 :::8042                 :::*                    LISTEN      1001       33369       6825/java       
</span><span class='line'>tcp6       0      0 :::8080                 :::*                    LISTEN      1001       33367       6825/java       
</span><span class='line'>tcp6       0      0 :::8088                 :::*                    LISTEN      1001       32771       6594/java       
</span><span class='line'>tcp6       0      0 :::8030                 :::*                    LISTEN      1001       32823       6594/java       
</span><span class='line'>tcp6       0      0 :::8031                 :::*                    LISTEN      1001       32779       6594/java       
</span><span class='line'>tcp6       0      0 :::8032                 :::*                    LISTEN      1001       32831       6594/java       
</span><span class='line'>tcp6       0      0 :::8033                 :::*                    LISTEN      1001       32843       6594/java       
</span><span class='line'>tcp6       0      0 :::8040                 :::*                    LISTEN      1001       33363       6825/java       
</span><span class='line'>tcp6       0      0 :::37896                :::*                    LISTEN      1001       33353       6825/java       
</span><span class='line'>hduser@ubuntu:~/hadoop-2.0.5-alpha/logs$</span></code></pre></td></tr></table></div></figure>


<h2>11) Web界面</h2>

<ul>
<li>查看HDFS及其health信息</li>
</ul>


<p><a href="http://132.253.222.240:50070">http://132.253.222.240:50070</a> 或者 <a href="http://132.253.222.240:50070/dfshealth.jsp">http://132.253.222.240:50070/dfshealth.jsp</a></p>

<ul>
<li>查看Hadoop All Applications：</li>
</ul>


<p><a href="http://132.253.222.240:8088">http://132.253.222.240:8088</a> 或者 <a href="http://132.253.222.240:8088/cluster">http://132.253.222.240:8088/cluster</a></p>

<p>(这里的IP请使用localhost或者自己的对应IP，我所使用的是Ubuntu CMD)</p>

<h4>待解问题：</h4>

<ul>
<li><p>what&rsquo;s YARN ?</p></li>
<li><p>what&rsquo;s jps ?</p></li>
</ul>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/07/25/python-leanring-resources/">Python学习的资源</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-07-25T21:09:03-07:00" pubdate data-updated="true">Jul 25<span>th</span>, 2013</time>
        
      </p>
    
  </header>


  <div class="entry-content"><ul>
<li><em>啄木鸟社区</em> [link, <a href="http://woodpecker.org.cn/">http://woodpecker.org.cn/</a>]</li>
</ul>


<p>(里面内容分为：
&ndash; Wiki
&ndash; Planet
&ndash; 简明Python 2.3教程
&ndash; 简明Python 3教程
&ndash; Dive Into Python中文版
&ndash; Dive Into Python 3中文版
)</p>

<ul>
<li>《深入Python3》 [link, <a href="http://woodpecker.org.cn/diveintopython3/index.html">http://woodpecker.org.cn/diveintopython3/index.html</a>]</li>
</ul>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/07/19/how-to-do-perfermance-tuning/">如何做好性能测试/调优</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-07-19T21:09:03-07:00" pubdate data-updated="true">Jul 19<span>th</span>, 2013</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>性能调优，需要了解的知识点和面包括：</p>

<ul>
<li>Java</li>
<li>数据库</li>
<li>网络</li>
<li>通讯机制</li>
<li>Apache</li>
<li>Tomcat</li>
<li>JVM</li>
</ul>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/07/18/learn-git-online/">在线学习GIT</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-07-18T21:09:03-07:00" pubdate data-updated="true">Jul 18<span>th</span>, 2013</time>
        
      </p>
    
  </header>


  <div class="entry-content"><ul>
<li>Try-Git 10 分钟教程 [<a href="http://try.github.io/wrap_up">http://try.github.io/wrap_up</a>]</li>
<li>Git Real at Code School &ndash; Level 1 [<a href="http://gitreal.codeschool.com/levels/1">http://gitreal.codeschool.com/levels/1</a>]</li>
</ul>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/07/17/my-eclipse-plugins/">My Eclipse Plugins</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-07-17T23:09:03-07:00" pubdate data-updated="true">Jul 17<span>th</span>, 2013</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>&mdash;filename: 2013_07_17_my_eclipse_plugins.md</p>

<h2>My Eclipse Plugins</h2>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/07/17/different-way-to-reverse-java-to-uml/">Different_way_to_reverse_java_to_uml</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-07-17T21:09:03-07:00" pubdate data-updated="true">Jul 17<span>th</span>, 2013</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h2>different_way_to_reverse_java_to_uml.md</h2>

<p>常用的几种方式</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/07/16/list-of-china-movie-name-abroad/">国内电影 外名列表</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-07-16T21:09:03-07:00" pubdate data-updated="true">Jul 16<span>th</span>, 2013</time>
        
      </p>
    
  </header>


  <div class="entry-content"><ul>
<li>英雄本色 &ndash; A Better Tomorrow</li>
<li>国产凌凌漆 &ndash; From Beijing with Love</li>
<li>活着 &ndash; To Live</li>
<li>TBD</li>
</ul>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/07/14/should-build-my-booklist/">应该建立我自己的读书目录</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-07-14T21:09:03-07:00" pubdate data-updated="true">Jul 14<span>th</span>, 2013</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>有很多电子书，读过了并没有记下多少东西，有些书很有用、但是还没有读过，而自己也没有有效的分类方式。</p>

<p>建立状态表格：</p>

<ul>
<li>书名 磁盘名 笔记链接 是否已读 阅读进度</li>
<li>A</li>
<li>B</li>
</ul>


<p>TBD.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/07/13/command-to-see-ubuntu-64-or-32/">查看Ubuntu系统是否64位</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-07-13T21:09:03-07:00" pubdate data-updated="true">Jul 13<span>th</span>, 2013</time>
        
      </p>
    
  </header>


  <div class="entry-content"><ul>
<li>1.$uname -a</li>
</ul>


<p>如果有x86_64就是64位的，没有就是32位的</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>vincent@ubuntu:~$ uname -a 
</span><span class='line'>Linux ubuntu 3.2.0-23-generic-pae #36-Ubuntu SMP Tue Apr 10 22:19:09 UTC 2012 i686 i686 i386 GNU/Linux</span></code></pre></td></tr></table></div></figure>


<ul>
<li>2.$ uname -m</li>
</ul>


<p>x86_64</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>vincent@ubuntu:~$ uname -m
</span><span class='line'>i686</span></code></pre></td></tr></table></div></figure>


<ul>
<li>3.$ arch</li>
</ul>


<p>x86_64</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>vincent@ubuntu:~$ arch
</span><span class='line'>i686</span></code></pre></td></tr></table></div></figure>


<ul>
<li>4.$file /bin/cat</li>
</ul>


<p>/bin/cat: ELF 64-bit LSB executable, AMD x86-64, version 1 (SYSV), for GNU/Linux 2.4.0, dynamically linked (uses shared libs), stripped</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>vincent@ubuntu:~$ file /bin/cat 
</span><span class='line'>/bin/cat: ELF 32-bit LSB executable, Intel 80386, version 1 (SYSV), dynamically linked (uses shared libs), for GNU/Linux 2.6.24, BuildID[sha1]=0x9e7f078dcc2d3dae02f578a1390debea06a26b74, stripped</span></code></pre></td></tr></table></div></figure>


<ul>
<li>5.查看cpu是多少位的</li>
</ul>


<p>more /proc/cpuinfo</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>vincent@ubuntu:~$ more /proc/cpuinfo 
</span><span class='line'>processor       : 0
</span><span class='line'>vendor_id       : GenuineIntel
</span><span class='line'>cpu family      : 6
</span><span class='line'>model           : 44
</span><span class='line'>model name      : Intel(R) Xeon(R) CPU           E5606  @ 2.13GHz
</span><span class='line'>stepping        : 2
</span><span class='line'>microcode       : 0x10
</span><span class='line'>cpu MHz         : 2128.070
</span><span class='line'>cache size      : 8192 KB
</span><span class='line'>fdiv_bug        : no
</span><span class='line'>hlt_bug         : no
</span><span class='line'>f00f_bug        : no
</span><span class='line'>coma_bug        : no
</span><span class='line'>fpu             : yes
</span><span class='line'>fpu_exception   : yes
</span><span class='line'>cpuid level     : 11
</span><span class='line'>wp              : yes
</span><span class='line'>flags           : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss nx rdt
</span><span class='line'>scp constant_tsc up pebs bts xtopology tsc_reliable aperfmperf pni pclmulqdq ssse3 sse4_1 sse4_2 popcnt aes hypervisor arat epb dts
</span><span class='line'>bogomips        : 4256.14
</span><span class='line'>clflush size    : 64
</span><span class='line'>cache_alignment : 64
</span><span class='line'>address sizes   : 40 bits physical, 48 bits virtual
</span><span class='line'>power management:</span></code></pre></td></tr></table></div></figure>


<ul>
<li>6.file /sbin/init</li>
</ul>


<p>/sbin/init: ELF 32-bit LSB executable, Intel 80386, version 1 (SYSV),</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>vincent@ubuntu:~$ file /sbin/init
</span><span class='line'>/sbin/init: ELF 32-bit LSB shared object, Intel 80386, version 1 (SYSV), dynamically linked (uses shared libs), for GNU/Linux 2.6.24, BuildID[sha1]=0x0ec7a63bbdb983cd488002f4cb87cdc0de5596f8, stripped</span></code></pre></td></tr></table></div></figure>


<p>EOF.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/07/11/putty_to_connect_to_ubuntu_vm/">2013-07-11-putty_to_connect_to_ubuntu_vm</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-07-11T13:09:03-07:00" pubdate data-updated="true">Jul 11<span>th</span>, 2013</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h2>Putty连接VM中的Ubuntu问题及解决</h2>

<p>问题：</p>

<p>VMWare中安装了Ubuntu，通过配置使其命令行模式启动；启动后通过$ifconfig获得其IP，通过Putty中设置IP、Port 22 访问报错，错误信息“不会出现登录界面，几秒钟后弹出窗口-Network error : Connection Refused”.</p>

<p>解决：</p>

<ol>
<li>可能没有开启ssh-server服务：</li>
</ol>


<p>命令$ sudo apt-get install openssh-server</p>

<p>安装成功；之后还是之前同样的错误、不能Putty连接；</p>

<ol>
<li>安装openssh-client，但是Ubuntu缺省已经安装了openssh-client。</li>
</ol>


<p>$sudo apt-get insall openssh-client</p>

<ol>
<li>确认sshserver已经启动：</li>
</ol>


<p>$ps -e | grep ssh</p>

<p>如果没有看到ssh，则手动启动 $sudo /etc/init.d/ssh start (or $sudo service ssh start)</p>

<ol>
<li>Putty依旧不能访问</li>
</ol>


<p>关闭windows7防火墙，全部关闭，应该是windows禁止了通过22端口访问；可以连接成功。</p>

<ol>
<li>VM Ubuntu端口改变问题</li>
</ol>


<p>配置成功后，通过Putty连接没有问题，但是发现每过一段时间，就回出现连接丢失的现象；几次三番后，发现其IP在动态改变；解决办法是在VM Setting中修改Network Adapter方式，NAT &ndash;> Bridged。</p>

<p>（NAT: Used to share the host&rsquo;s IP address; Bridged: Connected directly to the physical network）</p>

<ol>
<li>其它说明</li>
</ol>


<p>ssh-server配置文件位于/etc/ssh/sshd_config文件，可以修改ssh的服务端口，默认是22,；修改后重启ssh服务： $sudo /etc/init.d/ssh restart</p>

<ol>
<li>遗留问题</li>
</ol>


<p>只能通过IP+Port的方式访问，如何才能通过hostname访问呢？</p>

<ol>
<li>JDK下载，通过curl</li>
</ol>


<p>8.1 安装 curl：$sudo apt-get curl</p>

<p>8.2 how to download Oracle JDK without browser: [<a href="https://gist.github.com/hgomez/4697585">https://gist.github.com/hgomez/4697585</a>]</p>

<p>8.3 使用SecureCRT所带SFTP上传JDK至Ubuntu，版本jdk-7u25-linux-i586.tar.gz</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>vincent@ubuntu:~$ tar -xf jdk-7u25-linux-i586.tar.gz 
</span><span class='line'>vincent@ubuntu:~$ ls
</span><span class='line'>Desktop    examples.desktop            Music     Templates
</span><span class='line'>Documents  jdk1.7.0_25                 Pictures  Videos
</span><span class='line'>Downloads  jdk-7u25-linux-i586.tar.gz  Public
</span><span class='line'>vincent@ubuntu:~$ cd jdk1.7.0_25/
</span><span class='line'>vincent@ubuntu:~/jdk1.7.0_25$ cd bin
</span><span class='line'>vincent@ubuntu:~/jdk1.7.0_25/bin$ ./java -version
</span><span class='line'>java version "1.7.0_25"
</span><span class='line'>Java(TM) SE Runtime Environment (build 1.7.0_25-b15)
</span><span class='line'>Java HotSpot(TM) Client VM (build 23.25-b01, mixed mode)</span></code></pre></td></tr></table></div></figure>


<p>配置JDK variables</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>vincent@ubuntu:~$ vi .bashrc
</span><span class='line'>
</span><span class='line'># export my own variables
</span><span class='line'>JAVA_HOME=/home/vincent/jdk1.7.0_25
</span><span class='line'>export JAVA_HOME
</span><span class='line'>PATH=$PATH:$JAVA_HOME/bin
</span><span class='line'>export PATH
</span><span class='line'>
</span><span class='line'>vincent@ubuntu:~$ source .bashrc
</span><span class='line'>vincent@ubuntu:~$ java -version
</span><span class='line'>java version "1.7.0_25"
</span><span class='line'>Java(TM) SE Runtime Environment (build 1.7.0_25-b15)
</span><span class='line'>Java HotSpot(TM) Client VM (build 23.25-b01, mixed mode)</span></code></pre></td></tr></table></div></figure>


<ol>
<li>安装Hadoop</li>
</ol>


<p>9.1 [下载地址, <a href="http://mirror.cogentco.com/pub/apache/hadoop/common/hadoop-2.0.5-alpha/">http://mirror.cogentco.com/pub/apache/hadoop/common/hadoop-2.0.5-alpha/</a>]</p>

<p>9.2 Setting up a Single Node Cluster, follow <B>Running Hadoop on Ubuntu Linux (Single-Node Cluster)</B> [<a href="http://www.michael-noll.com/tutorials/running-hadoop-on-ubuntu-linux-single-node-cluster/">http://www.michael-noll.com/tutorials/running-hadoop-on-ubuntu-linux-single-node-cluster/</a>]</p>

<blockquote><p> The main goal of this tutorial is to get a simple Hadoop installation up and running so that you can play around with the software and learn more about it.</p></blockquote>

<p>9.3 添加Hadoop专用user</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>vincent@ubuntu:~$ sudo addgroup hadoop
</span><span class='line'>[sudo] password for vincent: 
</span><span class='line'>Adding group `hadoop' (GID 1001) ...
</span><span class='line'>Done.
</span><span class='line'>vincent@ubuntu:~$ sudo adduser --ingroup hadoop hduser
</span><span class='line'>Adding user `hduser' ...
</span><span class='line'>Adding new user `hduser' (1001) with group `hadoop' ...
</span><span class='line'>Creating home directory `/home/hduser' ...
</span><span class='line'>Copying files from `/etc/skel' ...
</span><span class='line'>Enter new UNIX password: 
</span><span class='line'>Retype new UNIX password: 
</span><span class='line'>Sorry, passwords do not match
</span><span class='line'>passwd: Authentication token manipulation error
</span><span class='line'>passwd: password unchanged
</span><span class='line'>Try again? [y/N] y
</span><span class='line'>Enter new UNIX password: 
</span><span class='line'>Retype new UNIX password: 
</span><span class='line'>passwd: password updated successfully
</span><span class='line'>Changing the user information for hduser
</span><span class='line'>Enter the new value, or press ENTER for the default
</span><span class='line'>        Full Name []: hadoop user
</span><span class='line'>        Room Number []: 
</span><span class='line'>        Work Phone []: 
</span><span class='line'>        Home Phone []: 
</span><span class='line'>        Other []: 
</span><span class='line'>Is the information correct? [Y/n] y</span></code></pre></td></tr></table></div></figure>


<p>9.4 需要设置SSH远程自动登录，需要其他机器直接访问Hadoop node，configure it to allow SSH public key authentication. 参考[Ubuntu Guide, <a href="http://ubuntuguide.org/wiki/Ubuntu_Raring">http://ubuntuguide.org/wiki/Ubuntu_Raring</a>]</p>

<ul>
<li>(这个时候，考虑，是不是之前使用user vincent配置了Java环境变量是不是不对、应该配置为全局变量？ 后面再看。)</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>hduser@ubuntu:~$ ssh-keygen -t rsa -P ""
</span><span class='line'>Generating public/private rsa key pair.
</span><span class='line'>Enter file in which to save the key (/home/hduser/.ssh/id_rsa): 
</span><span class='line'>Created directory '/home/hduser/.ssh'.
</span><span class='line'>Your identification has been saved in /home/hduser/.ssh/id_rsa.
</span><span class='line'>Your public key has been saved in /home/hduser/.ssh/id_rsa.pub.
</span><span class='line'>The key fingerprint is:
</span><span class='line'>9f:28:f3:80:ae:6c:64:d6:78:74:74:67:fa:21:91:f3 hduser@ubuntu
</span><span class='line'>The key's randomart image is:
</span><span class='line'>+--[ RSA 2048]----+
</span><span class='line'>|         .       |
</span><span class='line'>|      . = o      |
</span><span class='line'>|     . . B       |
</span><span class='line'>|    . . o E      |
</span><span class='line'>|   + .  So .     |
</span><span class='line'>|  = o.   o..     |
</span><span class='line'>| + .. + . o      |
</span><span class='line'>| ...   =         |
</span><span class='line'>| .o..   .        |
</span><span class='line'>+-----------------+
</span><span class='line'>hduser@ubuntu:~$ ll
</span><span class='line'>hduser@ubuntu:~$ cat .ssh/id_rsa.pub &gt;&gt; .ssh/authorized_keys
</span><span class='line'>
</span><span class='line'>//测试是否可以无密码登录
</span><span class='line'>hduser@ubuntu:~/.ssh$ ssh localhost 
</span><span class='line'>The authenticity of host 'localhost (127.0.0.1)' can't be established.
</span><span class='line'>ECDSA key fingerprint is 47:6b:7b:a6:e4:80:38:96:f9:9c:a3:58:48:f4:51:82.
</span><span class='line'>Are you sure you want to continue connecting (yes/no)? yes
</span><span class='line'>Warning: Permanently added 'localhost' (ECDSA) to the list of known hosts.
</span><span class='line'>Welcome to Ubuntu 12.04 LTS (GNU/Linux 3.2.0-23-generic-pae i686)
</span><span class='line'>
</span><span class='line'> * Documentation:  https://help.ubuntu.com/
</span><span class='line'>
</span><span class='line'>Last login: Wed Jul 31 01:38:45 2013 from gjia2d.ptcnet.ptc.com
</span><span class='line'>hduser@ubuntu:~$ </span></code></pre></td></tr></table></div></figure>


<p>9.5 开始安装配置Hadoop</p>

<ul>
<li>配置Hadoop user hduser 加入sudo权限中（需要这一步么？todo……）</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>vincent@ubuntu:/etc$ cd /etc/
</span><span class='line'>vincent@ubuntu:/etc$ ll sudo*
</span><span class='line'>-r--r----- 1 root root  767 Jul 31 02:17 sudoers
</span><span class='line'>
</span><span class='line'>sudoers.d:
</span><span class='line'>total 20
</span><span class='line'>drwxr-xr-x   2 root root  4096 Apr 23  2012 ./
</span><span class='line'>drwxr-xr-x 127 root root 12288 Jul 31 02:17 ../
</span><span class='line'>-r--r-----   1 root root   753 Jan 31  2012 README
</span><span class='line'>vincent@ubuntu:/etc$ sudo vi sudoers
</span><span class='line'>
</span><span class='line'>// add sudo users
</span><span class='line'>hduser ALL=(ALL) ALL
</span><span class='line'>// sudoers文件的修改立即生效</span></code></pre></td></tr></table></div></figure>


<ul>
<li>添加Hadoop相关变量设置到hduser的$HOME/.bashrc</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>// vj, add Hadoop Variables
</span><span class='line'>hduser@ubuntu:~$ vi .bashrc
</span><span class='line'>
</span><span class='line'>HADOOP_HOME=/home/hduser/hadoop-2.0.5-alpha
</span><span class='line'>export HADOOP_HOME
</span><span class='line'>JAVA_HOME=/home/vincent/jdk1.7.0_25
</span><span class='line'>export JAVA_HOME
</span><span class='line'>
</span><span class='line'>//Some convenient aliases and functions for running Hadoop-related commands
</span><span class='line'>unalias fs &&gt; /dev/null
</span><span class='line'>alias fs="hadoop fs"
</span><span class='line'>unalias hls &&gt; /dev/null
</span><span class='line'>alias hls="fs -ls"
</span><span class='line'>
</span><span class='line'>PATH=$PATH:$HADOOP_HOME/bin
</span><span class='line'>export PATH
</span><span class='line'>
</span><span class='line'>hduser@ubuntu:~$ hadoop version
</span><span class='line'>Hadoop 2.0.5-alpha
</span><span class='line'>Subversion http://svn.apache.org/repos/asf/hadoop/common -r 1488459
</span><span class='line'>Compiled by jenkins on 2013-06-01T04:05Z
</span><span class='line'>From source with checksum c8f4bd45ac25c31b815f311b32ef17
</span><span class='line'>This command was run using /home/hduser/hadoop-2.0.5-alpha/share/hadoop/common/hadoop-common-2.0.5-alpha.jar</span></code></pre></td></tr></table></div></figure>


<ul>
<li>配置并运行起Hadoop，请看<a href="./2013-08-01-single-node-setup-of-hadoop.md">下一篇 &ndash; Single-Node setup of Hadoop</a></li>
</ul>


<p>TODO：</p>

<ul>
<li>当前时间显示是PDT时区(Wed Jul 31 01:46:14 PDT 2013)，如何配置显示东八区时间？</li>
</ul>


<p>补充资料：</p>

<ul>
<li><p>Ubuntu Environment Variables (link, <a href="https://help.ubuntu.com/community/EnvironmentVariables">https://help.ubuntu.com/community/EnvironmentVariables</a>)</p></li>
<li><h3>What&rsquo;s Hadoop Distributed File System (HDFS)</h3></li>
</ul>


<blockquote><p>The Hadoop Distributed File System (HDFS) is a distributed file system designed to run on commodity hardware. It has many similarities with existing distributed file systems. However, the differences from other distributed file systems are significant. HDFS is highly fault-tolerant and is designed to be deployed on low-cost hardware. HDFS provides high throughput access to application data and is suitable for applications that have large data sets. HDFS relaxes a few POSIX requirements to enable streaming access to file system data. HDFS was originally built as infrastructure for the Apache Nutch web search engine project. HDFS is part of the Apache Hadoop project, which is part of the Apache Lucene project.</p>

<p><I><B>The Hadoop Distributed File System: Architecture and Design</B> &ndash; <a href="http://hadoop.apache.org/hdfs/docs/current/hdfs_design.html">hadoop.apache.org/hdfs/docs/…</a></I></p></blockquote>

<p>The following picture gives an overview of the most important HDFS components.</p>

<p><img src="../images/HDFS-Architecture.gif" title="Optional title" alt="HDFS Architecture" /></p>

<p>EOF.</p>
</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/blog/page/4/">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
    <a class="next" href="/blog/page/2/">Newer &rarr;</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2014/01/27/how-to-find-the-lost-chrome-bookmarks/">How to Find the Lost Chrome Bookmarks</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/01/23/reset-centos-root-password/">Reset Centos Root Password</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/11/22/test-and-come-on-post/">Test and Come on Post</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/11/22/another-post-to-poc/">Another Post to POC</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/11/22/a-first-blog-in-octopress/">A First Blog in Octopress</a>
      </li>
    
  </ul>
</section>





  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2014 - Vincent J -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = '//platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
